{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Part 3 - Training Neural Networks (Exercises).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "363c4b43a2924d099ef4966643ff38b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3449542f5e9464c941d53d1db040fe8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ed0de3fe77148f7985e1ce445699804",
              "IPY_MODEL_dfc2b04369464dd0bc663c818f4b8e53"
            ]
          }
        },
        "c3449542f5e9464c941d53d1db040fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ed0de3fe77148f7985e1ce445699804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e4fd7c4bb3f4d6a89afb14a72f83504",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0670bde1df8439c81adb15281795e99"
          }
        },
        "dfc2b04369464dd0bc663c818f4b8e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54eccd8e84ed4222aafe2265d54352fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [05:51&lt;00:00, 28242.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_050848ee287f430c8a1bcdb764df1f69"
          }
        },
        "9e4fd7c4bb3f4d6a89afb14a72f83504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0670bde1df8439c81adb15281795e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54eccd8e84ed4222aafe2265d54352fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "050848ee287f430c8a1bcdb764df1f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a398f1f847be4d508d4de3a8068274ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fda3721386484b628659474c677215a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eebd9cdb0e594e7cb1c537bd8753f302",
              "IPY_MODEL_399e08e766ee43ef8ce5e8d296b21ba5"
            ]
          }
        },
        "fda3721386484b628659474c677215a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eebd9cdb0e594e7cb1c537bd8753f302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa98e955390c427a85372d5a7f62dd74",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33261650180542fdbbce652f33f84a1e"
          }
        },
        "399e08e766ee43ef8ce5e8d296b21ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f60bb98cb4db4066b98646aadff7d996",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:51&lt;00:00, 575.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8a0dd6a1f244f75b829ab2f2e36adb1"
          }
        },
        "fa98e955390c427a85372d5a7f62dd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33261650180542fdbbce652f33f84a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f60bb98cb4db4066b98646aadff7d996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8a0dd6a1f244f75b829ab2f2e36adb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f96e2be137f04c86a15b8f835f7f7433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5c62aeed1744071be682090f2ddac7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b341adea3794b558646f46c7d720a06",
              "IPY_MODEL_fc4565a6d70a491db3bdb58bff719eff"
            ]
          }
        },
        "e5c62aeed1744071be682090f2ddac7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b341adea3794b558646f46c7d720a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_936eb4530ad342bdb5b1ad471848b5cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a96e062c23be42ccb3ca60f1035db67a"
          }
        },
        "fc4565a6d70a491db3bdb58bff719eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5147333b00e8400caed30064607f4c1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:51&lt;00:00, 32125.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f0c5d42fc5f4139abf5a11ffa5c3975"
          }
        },
        "936eb4530ad342bdb5b1ad471848b5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a96e062c23be42ccb3ca60f1035db67a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5147333b00e8400caed30064607f4c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f0c5d42fc5f4139abf5a11ffa5c3975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f5353618ba74ff4bf859c4e6c401421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c806993dee7454d9f2d13924383589e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f2a5c652c0d47aab1b6e3f33be78a59",
              "IPY_MODEL_810232d7c486426392ab037a0fcc01ec"
            ]
          }
        },
        "0c806993dee7454d9f2d13924383589e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f2a5c652c0d47aab1b6e3f33be78a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16f218de0fc44b42b5aa6b11cde7ce1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a649aaea95894208b6012319cdc54ce3"
          }
        },
        "810232d7c486426392ab037a0fcc01ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b75d8d1a1fe64168b32fb9d83c33ffd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 39525.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6824df27ba7041adad8340c0196c71dc"
          }
        },
        "16f218de0fc44b42b5aa6b11cde7ce1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a649aaea95894208b6012319cdc54ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b75d8d1a1fe64168b32fb9d83c33ffd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6824df27ba7041adad8340c0196c71dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m29ZVVBunpvu"
      },
      "source": [
        "# Training Neural Networks\n",
        "\n",
        "The network we built in the previous part isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
        "\n",
        "<img src=\"assets/function_approx.png\" width=500px>\n",
        "\n",
        "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
        "\n",
        "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
        "\n",
        "$$\n",
        "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
        "$$\n",
        "\n",
        "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
        "\n",
        "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
        "\n",
        "<img src='assets/gradient_descent.png' width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NExym7S6npv6"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "For single layer networks, gradient descent is straightforward to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks.\n",
        "\n",
        "Training multilayer networks is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
        "\n",
        "<img src='assets/backprop_diagram.png' width=550px>\n",
        "\n",
        "In the forward pass through the network, our data and operations go from bottom to top here. We pass the input $x$ through a linear transformation $L_1$ with weights $W_1$ and biases $b_1$. The output then goes through the sigmoid operation $S$ and another linear transformation $L_2$. Finally we calculate the loss $\\ell$. We use the loss as a measure of how bad the network's predictions are. The goal then is to adjust the weights and biases to minimize the loss.\n",
        "\n",
        "To train the weights with gradient descent, we propagate the gradient of the loss backwards through the network. Each operation has some gradient between the inputs and outputs. As we send the gradients backwards, we multiply the incoming gradient with the gradient for the operation. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
        "\n",
        "$$\n",
        "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
        "$$\n",
        "\n",
        "**Note:** I'm glossing over a few details here that require some knowledge of vector calculus, but they aren't necessary to understand what's going on.\n",
        "\n",
        "We update our weights using this gradient with some learning rate $\\alpha$. \n",
        "\n",
        "$$\n",
        "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
        "$$\n",
        "\n",
        "The learning rate $\\alpha$ is set such that the weight update steps are small enough that the iterative method settles in a minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5JEhG8Bnpv9"
      },
      "source": [
        "## Losses in PyTorch\n",
        "\n",
        "Let's start by seeing how we calculate the loss with PyTorch. Through the `nn` module, PyTorch provides losses such as the cross-entropy loss (`nn.CrossEntropyLoss`). You'll usually see the loss assigned to `criterion`. As noted in the last part, with a classification problem such as MNIST, we're using the softmax function to predict class probabilities. With a softmax output, you want to use cross-entropy as the loss. To actually calculate the loss, you first define the criterion then pass in the output of your network and the correct labels.\n",
        "\n",
        "Something really important to note here. Looking at [the documentation for `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
        "\n",
        "> This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class.\n",
        ">\n",
        "> The input is expected to contain scores for each class.\n",
        "\n",
        "This means we need to pass in the raw output of our network into the loss, not the output of the softmax function. This raw output is usually called the *logits* or *scores*. We use the logits because softmax gives you probabilities which will often be very close to zero or one but floating-point numbers can't accurately represent values near zero or one ([read more here](https://docs.python.org/3/tutorial/floatingpoint.html)). It's usually best to avoid doing calculations with probabilities, typically we use log-probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532,
          "referenced_widgets": [
            "363c4b43a2924d099ef4966643ff38b8",
            "c3449542f5e9464c941d53d1db040fe8",
            "0ed0de3fe77148f7985e1ce445699804",
            "dfc2b04369464dd0bc663c818f4b8e53",
            "9e4fd7c4bb3f4d6a89afb14a72f83504",
            "c0670bde1df8439c81adb15281795e99",
            "54eccd8e84ed4222aafe2265d54352fb",
            "050848ee287f430c8a1bcdb764df1f69",
            "a398f1f847be4d508d4de3a8068274ac",
            "fda3721386484b628659474c677215a7",
            "eebd9cdb0e594e7cb1c537bd8753f302",
            "399e08e766ee43ef8ce5e8d296b21ba5",
            "fa98e955390c427a85372d5a7f62dd74",
            "33261650180542fdbbce652f33f84a1e",
            "f60bb98cb4db4066b98646aadff7d996",
            "a8a0dd6a1f244f75b829ab2f2e36adb1",
            "f96e2be137f04c86a15b8f835f7f7433",
            "e5c62aeed1744071be682090f2ddac7a",
            "7b341adea3794b558646f46c7d720a06",
            "fc4565a6d70a491db3bdb58bff719eff",
            "936eb4530ad342bdb5b1ad471848b5cd",
            "a96e062c23be42ccb3ca60f1035db67a",
            "5147333b00e8400caed30064607f4c1a",
            "9f0c5d42fc5f4139abf5a11ffa5c3975",
            "3f5353618ba74ff4bf859c4e6c401421",
            "0c806993dee7454d9f2d13924383589e",
            "3f2a5c652c0d47aab1b6e3f33be78a59",
            "810232d7c486426392ab037a0fcc01ec",
            "16f218de0fc44b42b5aa6b11cde7ce1e",
            "a649aaea95894208b6012319cdc54ce3",
            "b75d8d1a1fe64168b32fb9d83c33ffd6",
            "6824df27ba7041adad8340c0196c71dc"
          ]
        },
        "id": "x52baaHynpv-",
        "outputId": "f77f5225-9ca6-4d28-fb67-9665bd84af24"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "363c4b43a2924d099ef4966643ff38b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a398f1f847be4d508d4de3a8068274ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f96e2be137f04c86a15b8f835f7f7433",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f5353618ba74ff4bf859c4e6c401421",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33_KgTaGnpwE"
      },
      "source": [
        "### Note\n",
        "If you haven't seen `nn.Sequential` yet, please finish the end of the Part 2 notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a43YIVgtnpwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8719ce8-61be-4576-c95b-a50d8bce0dce"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "\n",
        "print(loss)\n",
        "logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2930, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.9216e-02, -1.1891e-01, -3.8274e-02,  6.9754e-02,  3.0691e-02,\n",
              "          2.2124e-01, -1.0451e-01, -7.0336e-03,  2.0373e-02, -5.4828e-02],\n",
              "        [ 9.5619e-02, -5.4369e-02, -6.6252e-02, -4.0537e-02, -2.3300e-03,\n",
              "          1.3529e-01, -1.8702e-01,  1.8242e-02,  9.3855e-02, -5.3233e-02],\n",
              "        [ 5.2688e-02, -1.5814e-01, -4.3796e-02,  7.8318e-02, -1.6679e-02,\n",
              "          1.5184e-01, -8.2188e-02, -8.2277e-03,  2.2819e-02, -5.0974e-02],\n",
              "        [ 1.1170e-01, -1.6809e-01, -1.8898e-02,  1.4902e-01, -1.5601e-03,\n",
              "          1.3955e-01, -1.9390e-03,  1.3872e-02,  4.3727e-02, -1.0838e-01],\n",
              "        [ 1.9893e-02, -1.2259e-01, -1.1968e-01,  9.4544e-03,  1.5759e-02,\n",
              "          1.5514e-01, -1.2506e-01,  2.3202e-02,  1.0538e-01, -7.3287e-02],\n",
              "        [ 9.1201e-02, -1.5849e-01, -1.0149e-01,  2.1467e-02, -3.0119e-02,\n",
              "          1.6198e-01, -1.0301e-01,  2.9557e-02,  9.1800e-02, -8.0263e-02],\n",
              "        [ 1.2500e-02, -1.3439e-01, -9.2411e-02,  2.4128e-02,  7.6173e-03,\n",
              "          1.8172e-01, -1.7370e-01, -1.0731e-02,  5.3782e-02, -2.9240e-02],\n",
              "        [ 8.8990e-02, -1.9951e-01, -4.1200e-02,  3.7256e-02,  2.6504e-02,\n",
              "          9.7856e-02, -5.0378e-02, -1.9265e-02,  1.0580e-02, -8.5844e-02],\n",
              "        [ 5.5865e-02, -1.0062e-01, -1.0339e-02,  9.8337e-02,  1.0769e-02,\n",
              "          2.2553e-01, -6.7532e-02,  5.1517e-03,  6.8430e-02, -3.4390e-02],\n",
              "        [ 6.2010e-02, -1.4760e-01, -9.3346e-02, -2.6008e-03, -4.0398e-02,\n",
              "          1.1419e-01, -1.8027e-01, -2.2022e-04,  3.6139e-02, -2.4770e-02],\n",
              "        [ 1.3014e-01, -1.0173e-01, -1.0742e-01,  5.3254e-02,  7.0032e-02,\n",
              "          9.9447e-02, -8.2367e-02, -7.8404e-03,  2.4806e-02, -7.6979e-02],\n",
              "        [ 1.2065e-01, -1.2007e-01, -6.8374e-02,  1.5645e-02,  4.9350e-02,\n",
              "          1.4078e-01, -9.7057e-02,  8.2668e-03,  6.8078e-02, -9.3470e-02],\n",
              "        [ 7.9810e-02, -8.9814e-02, -5.5388e-02, -2.2177e-03, -8.4964e-02,\n",
              "          1.2140e-01, -1.3678e-01, -2.2394e-02,  7.6314e-02, -2.2956e-02],\n",
              "        [ 1.0920e-01, -1.0803e-01, -2.6032e-02,  1.7404e-01,  1.3514e-01,\n",
              "          1.2742e-01,  2.0989e-02, -5.9765e-03, -1.7654e-02, -1.5398e-01],\n",
              "        [ 4.7185e-02, -1.4410e-01, -7.6032e-02, -3.8838e-02, -2.7658e-02,\n",
              "          1.7212e-01, -1.3310e-01,  6.3073e-03,  8.6291e-02, -3.0963e-02],\n",
              "        [ 7.8061e-02, -1.3594e-01, -1.0750e-01, -2.8784e-02,  1.0412e-01,\n",
              "          5.8882e-02, -8.7640e-02, -2.9315e-02,  5.8553e-02, -6.5613e-02],\n",
              "        [ 1.0184e-01, -1.1227e-01, -9.4180e-03,  5.0234e-02,  1.2733e-02,\n",
              "          1.4578e-01, -2.7522e-02, -2.7453e-02,  7.2319e-02, -3.6424e-02],\n",
              "        [ 1.1443e-01, -1.9275e-01, -4.6796e-02,  4.3142e-02,  2.8489e-02,\n",
              "          1.3769e-01, -1.0363e-01, -4.8422e-04,  2.3373e-02, -8.3940e-02],\n",
              "        [ 1.6497e-02, -1.4534e-01, -1.1269e-01, -2.6678e-02, -4.7005e-02,\n",
              "          1.9228e-01, -1.6477e-01, -6.1920e-03,  1.0874e-01, -8.6546e-03],\n",
              "        [ 8.2020e-02, -1.4424e-01, -4.3684e-02,  9.4421e-03, -2.8521e-02,\n",
              "          1.1032e-01, -7.7625e-02,  8.9814e-03,  5.7187e-02,  1.1517e-02],\n",
              "        [ 2.4471e-02, -1.5000e-01, -1.2601e-01, -6.2028e-02, -6.0326e-03,\n",
              "          2.0185e-01, -1.6466e-01,  1.0141e-03,  1.3399e-01,  1.2015e-02],\n",
              "        [ 1.3167e-01, -9.1917e-02, -4.0409e-02,  5.8848e-02,  8.2127e-03,\n",
              "          1.4223e-01, -1.5309e-01, -1.6958e-02,  4.7041e-02, -9.8206e-02],\n",
              "        [ 4.4629e-02, -8.2605e-02, -1.2463e-01, -2.7562e-02, -2.8940e-02,\n",
              "          1.5592e-01, -1.7673e-01,  6.6960e-03,  9.9521e-02, -2.6987e-02],\n",
              "        [ 1.1264e-01, -7.5420e-02, -2.8372e-02,  1.3251e-02,  9.1803e-03,\n",
              "          1.2647e-01, -1.6764e-01, -1.5258e-02,  5.9437e-02, -6.8687e-02],\n",
              "        [ 6.6502e-02, -1.4798e-01, -1.0639e-01,  4.9242e-02,  4.3353e-02,\n",
              "          1.5924e-01, -6.0911e-02,  1.4774e-02,  1.1150e-01, -8.5184e-02],\n",
              "        [ 9.4777e-02, -1.2671e-01, -5.0042e-02,  4.4476e-02, -5.5675e-02,\n",
              "          1.8860e-01, -1.5127e-01, -2.6276e-02,  3.4081e-02, -4.1372e-02],\n",
              "        [ 1.0790e-01, -1.8199e-01, -4.5351e-02, -3.3846e-02, -3.5317e-02,\n",
              "          1.0436e-01, -5.3690e-02, -6.9636e-03,  5.2753e-02, -5.5624e-02],\n",
              "        [ 8.5525e-02, -1.5272e-01, -4.9138e-02,  1.0524e-01,  8.6825e-02,\n",
              "          1.1087e-01,  2.5490e-02, -2.7844e-02,  1.1513e-01, -1.1482e-01],\n",
              "        [ 8.3020e-03, -9.0313e-02, -9.1970e-02, -3.1279e-03,  1.4512e-02,\n",
              "          1.5631e-01, -1.1819e-01,  1.7082e-02,  8.4261e-02, -6.4241e-02],\n",
              "        [ 8.1520e-02, -1.2071e-01, -4.0741e-02,  2.1179e-02, -4.1929e-02,\n",
              "          1.6776e-01, -9.6301e-02,  1.6659e-02,  9.1373e-02, -2.0812e-02],\n",
              "        [ 1.1958e-01, -6.7257e-02, -2.1570e-02, -5.2105e-03,  2.1312e-03,\n",
              "          1.3744e-01, -1.2660e-01, -6.9260e-03,  8.8110e-02, -2.5809e-02],\n",
              "        [ 9.1834e-02, -1.5108e-01, -3.0722e-02,  5.9819e-03,  2.9513e-02,\n",
              "          1.0686e-01, -8.7634e-02,  2.2002e-02,  9.5524e-02, -6.3189e-02],\n",
              "        [ 7.1389e-03, -1.0245e-01, -9.2880e-02, -2.7612e-02, -3.1359e-02,\n",
              "          1.9280e-01, -1.8850e-01, -6.0440e-02,  9.6905e-02, -3.0158e-02],\n",
              "        [ 4.8813e-02, -1.9467e-01, -6.2065e-02,  4.2270e-02, -1.5601e-02,\n",
              "          1.9266e-01, -9.1956e-02,  7.6071e-03,  7.3776e-02, -8.5641e-02],\n",
              "        [ 2.4906e-02, -1.1221e-01, -6.3585e-02,  5.5874e-02,  1.6106e-02,\n",
              "          1.8146e-01, -1.0381e-01, -4.0668e-03,  5.4314e-02, -6.6081e-02],\n",
              "        [ 7.4384e-02, -3.6708e-02, -1.7650e-02,  8.2254e-02,  4.9849e-02,\n",
              "          1.8364e-01, -8.4832e-02, -2.6227e-02,  3.9282e-02, -1.0086e-01],\n",
              "        [ 4.2149e-02, -1.3792e-01, -6.5410e-02,  1.9612e-02, -4.5024e-02,\n",
              "          1.9855e-01, -1.4003e-01, -3.2884e-03,  1.0183e-01, -4.6330e-02],\n",
              "        [ 6.6156e-02, -1.4510e-01, -7.5683e-02, -1.9888e-02,  9.5860e-03,\n",
              "          1.7056e-01, -1.3613e-01,  3.3941e-02,  8.8078e-02, -4.9191e-02],\n",
              "        [ 1.0427e-01, -1.4994e-01, -2.9304e-02,  7.1096e-02,  3.1627e-02,\n",
              "          1.3501e-01, -4.4655e-02,  2.4634e-02,  1.2598e-02, -5.9019e-02],\n",
              "        [ 1.7895e-02, -1.6026e-01, -1.0422e-01,  1.7851e-02, -2.3426e-03,\n",
              "          1.2918e-01, -1.3561e-01, -1.4975e-02,  5.1591e-02, -7.3936e-02],\n",
              "        [ 6.2292e-02, -1.7298e-01, -6.1748e-02,  4.3260e-02,  1.6308e-02,\n",
              "          1.0555e-01, -7.8883e-02, -1.8446e-02,  4.6044e-02, -7.7251e-02],\n",
              "        [ 2.3654e-03, -1.0567e-01, -2.0813e-02,  8.1494e-02,  1.8520e-02,\n",
              "          1.9145e-01, -1.4403e-01,  9.2874e-04,  9.9338e-02, -8.8495e-02],\n",
              "        [ 1.0920e-01, -1.8478e-01, -3.2620e-02,  4.9285e-02, -7.6202e-03,\n",
              "          8.5172e-02, -5.0159e-02, -1.5689e-02,  4.9427e-02, -3.0598e-02],\n",
              "        [ 9.3315e-02, -1.7830e-01, -1.9036e-02,  9.5158e-02,  2.1524e-02,\n",
              "          1.9985e-01, -1.2880e-01, -2.1329e-02,  8.5087e-02, -1.0036e-01],\n",
              "        [ 1.0866e-01, -7.6977e-02, -6.4749e-02,  2.3944e-02, -5.9055e-02,\n",
              "          9.2226e-02, -8.9836e-02, -4.9600e-02,  4.4805e-02, -6.7597e-02],\n",
              "        [ 8.0355e-02, -1.1190e-01, -7.4781e-02, -2.1350e-03, -1.0896e-01,\n",
              "          1.7559e-01, -1.6704e-01, -2.4707e-02,  6.6611e-02, -3.2436e-02],\n",
              "        [-1.8217e-02, -1.5262e-01, -1.1483e-01, -7.7222e-02, -4.8531e-02,\n",
              "          1.7628e-01, -2.1622e-01, -8.0777e-03,  1.5409e-01,  1.5671e-02],\n",
              "        [ 5.8876e-02, -1.3684e-01, -8.2343e-02,  2.3394e-02, -4.9202e-02,\n",
              "          1.3823e-01, -1.0374e-01,  1.1794e-03,  8.0171e-02, -3.2752e-02],\n",
              "        [ 6.6837e-02, -9.9039e-02, -9.7582e-02, -8.3037e-03, -7.4532e-02,\n",
              "          1.2046e-01, -1.5131e-01, -4.3659e-02,  1.3816e-01, -2.5606e-02],\n",
              "        [ 1.1228e-01, -1.3019e-01, -9.0818e-02,  4.8496e-02, -4.8533e-02,\n",
              "          1.3798e-01, -9.7207e-02, -8.1762e-02,  5.2335e-02, -6.2645e-02],\n",
              "        [ 8.4739e-02, -1.0166e-01, -2.7216e-02, -2.0752e-02, -2.4157e-02,\n",
              "          1.0323e-01, -6.9174e-02, -1.3605e-02,  1.0218e-01, -5.6738e-02],\n",
              "        [ 4.7806e-02, -1.2209e-01, -3.8755e-02,  2.3925e-02, -3.2098e-03,\n",
              "          1.8283e-01, -1.0925e-01, -1.1957e-02,  5.9788e-02, -7.6189e-02],\n",
              "        [ 1.1729e-01, -1.1633e-01, -9.5500e-02,  3.8254e-02, -4.6631e-02,\n",
              "          1.1294e-01, -1.1902e-01, -8.1760e-02,  7.0897e-02, -4.4646e-02],\n",
              "        [ 7.6656e-02, -9.8995e-02, -6.7736e-02,  3.6809e-02, -7.6313e-02,\n",
              "          1.4405e-01, -1.7180e-01, -4.0238e-02,  5.3992e-02, -1.5806e-02],\n",
              "        [ 6.8805e-02, -1.1606e-01, -6.4692e-02, -6.3769e-02, -1.0255e-01,\n",
              "          1.2639e-01, -1.8373e-01, -8.8700e-02,  1.4867e-01, -2.8816e-03],\n",
              "        [ 8.2534e-02, -8.3655e-02, -4.9975e-02,  1.1954e-01,  1.1344e-01,\n",
              "          1.3834e-01, -4.0102e-02, -2.6232e-02,  7.0413e-02, -1.0104e-01],\n",
              "        [ 7.6992e-02, -1.2941e-01, -9.0395e-02,  5.0506e-02, -8.2720e-02,\n",
              "          1.1675e-01, -1.5339e-01, -7.0500e-02,  7.4922e-02, -1.9106e-02],\n",
              "        [ 3.9639e-02, -1.9164e-01, -8.2759e-02, -7.1521e-04, -7.0672e-03,\n",
              "          1.8333e-01, -1.1324e-01, -4.5284e-02,  4.2088e-02, -8.4119e-02],\n",
              "        [ 9.9427e-02, -1.2615e-01, -1.5361e-01, -4.6622e-02, -3.6685e-02,\n",
              "          9.6392e-02, -1.2033e-01, -3.1473e-02,  6.5558e-02, -3.2081e-02],\n",
              "        [ 3.1856e-02, -1.6986e-01, -1.5059e-02,  7.5855e-02,  5.9800e-02,\n",
              "          1.8227e-01, -3.6020e-02,  1.9734e-03,  1.2468e-01, -4.9705e-02],\n",
              "        [ 4.1354e-02, -6.0335e-02, -3.5817e-02,  9.7447e-02, -2.9526e-02,\n",
              "          1.9339e-01, -1.3163e-01, -3.6476e-03,  4.0166e-02, -2.3847e-02],\n",
              "        [ 4.0731e-02, -1.6296e-01, -1.1777e-01,  7.8681e-03, -2.0136e-02,\n",
              "          1.5577e-01, -6.8971e-02,  4.3766e-02,  9.1627e-02, -3.0404e-02],\n",
              "        [ 6.0111e-02, -1.8289e-01, -4.3123e-02,  6.3656e-02,  1.1875e-02,\n",
              "          1.7625e-01, -4.6108e-02,  2.9221e-02,  7.5105e-02, -9.8891e-02],\n",
              "        [ 1.3068e-01, -1.2553e-01,  2.0222e-02,  7.3053e-02,  3.6138e-02,\n",
              "          1.6305e-01, -2.3098e-02,  1.8225e-02,  8.8114e-02, -3.7640e-02]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31ji2zZGnpwI"
      },
      "source": [
        "In my experience it's more convenient to build the model with a log-softmax output using `nn.LogSoftmax` or `F.log_softmax` ([documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax)). Then you can get the actual probabilities by taking the exponential `torch.exp(output)`. With a log-softmax output, you want to use the negative log likelihood loss, `nn.NLLLoss` ([documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)).\n",
        "\n",
        ">**Exercise:** Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for `nn.LogSoftmax` and `F.log_softmax` you'll need to set the `dim` keyword argument appropriately. `dim=0` calculates softmax across the rows, so each column sums to 1, while `dim=1` calculates across the columns so each row sums to 1. Think about what you want the output to be and choose `dim` appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjGXJUnVnpwJ",
        "outputId": "f5d453dc-6a05-4a22-dd7b-c9e8f5e30a26"
      },
      "source": [
        "# TODO: Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                      )\n",
        "\n",
        "# TODO: Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "### Run this to check your work\n",
        "# Get our data\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2979, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7jMmmZnnpwL"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
        "\n",
        "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
        "```python\n",
        "x = torch.zeros(1, requires_grad=True)\n",
        ">>> with torch.no_grad():\n",
        "...     y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "\n",
        "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
        "\n",
        "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeawvMr8npwj",
        "outputId": "5aaf4cba-c074-45ef-a394-be7a3734adb9"
      },
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5454, -0.2939],\n",
            "        [ 1.0030, -2.0769]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfs8ypZqnpwm",
        "outputId": "41958b21-2101-4e4c-f1cd-46966a60bb50"
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2974, 0.0864],\n",
            "        [1.0059, 4.3135]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUZr4hhlnpwo"
      },
      "source": [
        "Below we can see the operation that created `y`, a power operation `PowBackward0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgnlvXA_npwo",
        "outputId": "fab7674b-088d-4c92-8771-df9ab72dbd9d"
      },
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7fa23f05cd90>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX9J0kTlnpwp"
      },
      "source": [
        "The autograd module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0krhTHUnpwp",
        "outputId": "80c0f179-9133-49fc-e29e-687204a0ce10"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.4258, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNIByn96npwp"
      },
      "source": [
        "You can check the gradients for `x` and `y` but they are empty currently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBlEBldKnpwq",
        "outputId": "2e9a5287-c0db-49e3-fbac-9206a9fe2108"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5v1VV_Znpwq"
      },
      "source": [
        "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGjLyKWinpwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e652f4-ce39-4dc0-e1c4-b6480757c879"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2727, -0.1469],\n",
            "        [ 0.5015, -1.0384]])\n",
            "tensor([[ 0.2727, -0.1469],\n",
            "        [ 0.5015, -1.0384]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-S2JVHRnpwr"
      },
      "source": [
        "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the cost with respect to the weights. With PyTorch, we run data forward through the network to calculate the loss, then, go backwards to calculate the gradients with respect to the loss. Once we have the gradients we can make a gradient descent step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ8YQZoBnpwr"
      },
      "source": [
        "## Loss and Autograd together\n",
        "\n",
        "When we create a network with PyTorch, all of the parameters are initialized with `requires_grad = True`. This means that when we calculate the loss and call `loss.backward()`, the gradients for the parameters are calculated. These gradients are used to update the weights with gradient descent. Below you can see an example of calculating the gradients using a backwards pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyaFTC3Pnpwr"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logits = model(images)\n",
        "loss = criterion(logits, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5OTnrQtj9K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3af82d-5767-412b-9836-abd3e2463dce"
      },
      "source": [
        "i=0\n",
        "for x in trainloader:\n",
        "  i=i+1\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxWgkRFnnpws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccba9e4-53f8-404e-cf42-69b6449c4939"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n',model[0].weight.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0027, -0.0027, -0.0027,  ..., -0.0027, -0.0027, -0.0027],\n",
            "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
            "        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_diZHzWznpws"
      },
      "source": [
        "## Training the network!\n",
        "\n",
        "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html). For example we can use stochastic gradient descent with `optim.SGD`. You can see how to define an optimizer below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqo7rjYTnpws"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3QEdP16npwt"
      },
      "source": [
        "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
        "\n",
        "* Make a forward pass through the network \n",
        "* Use the network output to calculate the loss\n",
        "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
        "* Take a step with the optimizer to update the weights\n",
        "\n",
        "Below I'll go through one training step and print out the weights and gradients so you can see how it changes. Note that I have a line of code `optimizer.zero_grad()`. When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means that you need to zero the gradients on each training pass or you'll retain gradients from previous training batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWOhbtGWnpwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd51d710-5cdf-4e1b-bfba-9c13c4a637c2"
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[-0.0323,  0.0285, -0.0262,  ...,  0.0074,  0.0211, -0.0096],\n",
            "        [-0.0352,  0.0172,  0.0114,  ..., -0.0127,  0.0098,  0.0039],\n",
            "        [ 0.0301,  0.0191, -0.0290,  ...,  0.0355, -0.0118, -0.0255],\n",
            "        ...,\n",
            "        [-0.0278, -0.0107, -0.0148,  ...,  0.0198, -0.0069,  0.0339],\n",
            "        [ 0.0259,  0.0005,  0.0054,  ...,  0.0251,  0.0010,  0.0112],\n",
            "        [ 0.0292, -0.0298, -0.0285,  ..., -0.0140, -0.0059,  0.0094]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 9.4341e-05,  9.4341e-05,  9.4341e-05,  ...,  9.4341e-05,\n",
            "          9.4341e-05,  9.4341e-05],\n",
            "        [ 2.3585e-03,  2.3585e-03,  2.3585e-03,  ...,  2.3585e-03,\n",
            "          2.3585e-03,  2.3585e-03],\n",
            "        [ 5.7015e-04,  5.7015e-04,  5.7015e-04,  ...,  5.7015e-04,\n",
            "          5.7015e-04,  5.7015e-04],\n",
            "        ...,\n",
            "        [-1.6045e-04, -1.6045e-04, -1.6045e-04,  ..., -1.6045e-04,\n",
            "         -1.6045e-04, -1.6045e-04],\n",
            "        [-9.5030e-04, -9.5030e-04, -9.5030e-04,  ..., -9.5030e-04,\n",
            "         -9.5030e-04, -9.5030e-04],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm0gdWjnnpwt",
        "outputId": "57df2246-bad5-4468-fb5d-d50b5b8f9a34"
      },
      "source": [
        "# Take an update step and view the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[-0.0323,  0.0285, -0.0262,  ...,  0.0074,  0.0211, -0.0096],\n",
            "        [-0.0353,  0.0172,  0.0113,  ..., -0.0128,  0.0098,  0.0039],\n",
            "        [ 0.0301,  0.0191, -0.0290,  ...,  0.0355, -0.0118, -0.0255],\n",
            "        ...,\n",
            "        [-0.0278, -0.0107, -0.0148,  ...,  0.0198, -0.0069,  0.0339],\n",
            "        [ 0.0260,  0.0005,  0.0054,  ...,  0.0251,  0.0010,  0.0112],\n",
            "        [ 0.0292, -0.0298, -0.0285,  ..., -0.0140, -0.0059,  0.0094]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3k1FFrLnpwu"
      },
      "source": [
        "### Training for real\n",
        "\n",
        "Now we'll put this algorithm into a loop so we can go through all the images. Some nomenclature, one pass through the entire dataset is called an *epoch*. So here we're going to loop through `trainloader` to get our training batches. For each batch, we'll doing a training pass where we calculate the loss, do a backwards pass, and update the weights.\n",
        "\n",
        ">**Exercise:** Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "554ypD32npwu",
        "outputId": "0d7fb28f-e056-4337-95d6-7565974088e0"
      },
      "source": [
        "## Your solution here\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        # TODO: Training pass\n",
        "        loss = criterion(model(images),labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.830680002472294\n",
            "Training loss: 0.7903870477605222\n",
            "Training loss: 0.5130626712717227\n",
            "Training loss: 0.42413607946654625\n",
            "Training loss: 0.37991202859354933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMyuTJXSnpwu"
      },
      "source": [
        "With the network trained, we can check out it's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPOCb_Fdnpwv",
        "outputId": "e0840933-8582-44ab-c19f-ab9005866b8d"
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "img = images[0].view(1,784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "# helper.view_classify(img.view(1, 28, 28), ps)\n",
        "print(criterion(logps,labels[0].view(1)))\n",
        "print(ps,labels[0])\n",
        "print(torch.max(ps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0986)\n",
            "tensor([[6.2888e-05, 9.0614e-01, 1.8992e-02, 5.8641e-03, 1.8292e-03, 2.6364e-02,\n",
            "         1.6880e-02, 7.9543e-03, 1.0104e-02, 5.8122e-03]]) tensor(1)\n",
            "tensor(0.9061)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XkA9OdMnpwv"
      },
      "source": [
        "Now our network is brilliant. It can accurately predict the digits in our images. Next up you'll write the code for training a neural network on a more complex dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3DKQ93PIz3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16bf5f7-ab99-45e4-f53a-88ee69975a60"
      },
      "source": [
        "# random stuff\n",
        "m = nn.LogSoftmax(dim=1)\n",
        "loss = nn.NLLLoss()\n",
        "# input is of size N x C = 3 x 5\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "# each element in target has to have 0 <= value < C\n",
        "target = torch.tensor([1,0,2])\n",
        "output = loss(m(input), target)\n",
        "print(output)\n",
        "m(input)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.2843, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5590, -2.1631, -2.1471, -2.9714, -0.6800],\n",
              "        [-0.8397, -2.8558, -1.0762, -2.3759, -2.5659],\n",
              "        [-2.4586, -2.8167, -0.8502, -1.0161, -2.7291]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}